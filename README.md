# Riffusion_Trtion_TensorRT


### Inference Speed
![Inference Spee](https://github.com/daewoung/riffusion_triton_onnx/assets/96560111/116bd305-b71c-4f24-9469-6a873e940cf6)


### Batch Inference Speed
![Batch Inference Speed](https://github.com/daewoung/riffusion_triton_onnx/assets/96560111/b34959b7-1f85-43ab-9776-ec6792e0903d)
